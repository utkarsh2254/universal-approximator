##Neural Netwok as a universal approximator: Really?

The Universal approximation theorem states that a neural network model with just one hidden layer has the capability to approximate #ANY complex function. We know that the practicality of the above theorem is not as exciting as it sounds in theory. But still I have attempted to find out upto what extent a single layer neural network can learn a relatively complex function.
In this Ipython notebook, I've assumed the learning function to be sine function. One can play with the code and try learning different function, and using different number of hidden nodes in the hidden layer.
